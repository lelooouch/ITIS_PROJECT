name: üïê Scheduled Plagiarism Analysis

on:
  schedule:
    # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 6:00 –ø–æ UTC (9:00 –ø–æ –ú–æ—Å–∫–≤–µ)
    - cron: '0 6 * * *'
  workflow_dispatch:
    inputs:
      analysis_type:
        description: '–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞'
        required: false
        default: 'full'
        type: choice
        options:
          - 'quick'
          - 'full'
          - 'deep'
      threshold:
        description: '–ü–æ—Ä–æ–≥ –ø–ª–∞–≥–∏–∞—Ç–∞ (0.0-1.0)'
        required: false
        default: '0.7'
      notify_slack:
        description: '–û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Slack'
        required: false
        default: false
        type: boolean
      generate_report:
        description: '–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å PDF –æ—Ç—á–µ—Ç'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  pages: write
  id-token: write
  issues: write
  pull-requests: write

jobs:
  setup-environment:
    runs-on: ubuntu-latest
    outputs:
      run_id: ${{ steps.run_id.outputs.value }}
      timestamp: ${{ steps.timestamp.outputs.value }}
    steps:
      - name: Generate unique ID
        id: run_id
        run: echo "value=${{ github.run_id }}-${{ github.run_attempt }}" >> $GITHUB_OUTPUT
      
      - name: Generate timestamp
        id: timestamp
        run: echo "value=$(date +%Y%m%d_%H%M%S)" >> $GITHUB_OUTPUT
      
      - name: Print analysis info
        run: |
          echo "üîç –ó–∞–ø—É—Å–∫–∞—é –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–ª–∞–≥–∏–∞—Ç–∞"
          echo "   ID –∞–Ω–∞–ª–∏–∑–∞: ${{ steps.run_id.outputs.value }}"
          echo "   –í—Ä–µ–º—è: ${{ steps.timestamp.outputs.value }}"
          echo "   –¢–∏–ø: ${{ github.event.inputs.analysis_type || 'full' }}"
          echo "   –ü–æ—Ä–æ–≥: ${{ github.event.inputs.threshold || '0.7' }}"

  check-new-submissions:
    runs-on: ubuntu-latest
    needs: setup-environment
    outputs:
      has_new_files: ${{ steps.check.outputs.has_new_files }}
      file_count: ${{ steps.check.outputs.file_count }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Check for new submissions
        id: check
        run: |
          echo "üìÇ –ü—Ä–æ–≤–µ—Ä—è—é –Ω–æ–≤—ã–µ —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã..."
          
          # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É uploads –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
          mkdir -p uploads
          
          # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
          LAST_RUN=$(git log --oneline --grep="üìä Automated analysis" -1 --format="%H" 2>/dev/null || echo "")
          
          if [ -n "$LAST_RUN" ]; then
            # –°—á–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            NEW_FILES=$(git diff --name-only $LAST_RUN HEAD -- uploads/ | grep -E '\.(txt|pdf|docx)$' | wc -l)
          else
            # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - —Å—á–∏—Ç–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
            NEW_FILES=$(find uploads/ -type f -name "*.txt" -o -name "*.pdf" -o -name "*.docx" 2>/dev/null | wc -l)
          fi
          
          echo "–ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: $NEW_FILES"
          
          if [ "$NEW_FILES" -gt 0 ]; then
            echo "has_new_files=true" >> $GITHUB_OUTPUT
            echo "file_count=$NEW_FILES" >> $GITHUB_OUTPUT
            
            # –ü–µ—Ä–µ—á–∏—Å–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            echo "üìÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:"
            find uploads/ -type f -name "*.txt" -o -name "*.pdf" -o -name "*.docx" 2>/dev/null || echo "–ù–µ—Ç —Ñ–∞–π–ª–æ–≤"
          else
            echo "has_new_files=false" >> $GITHUB_OUTPUT
            echo "file_count=0" >> $GITHUB_OUTPUT
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            echo "–ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏..."
            mkdir -p uploads_demo
            cp -r data/sample_essays/* uploads_demo/ 2>/dev/null || echo "–ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω—ã"
          fi

  run-plagiarism-analysis:
    runs-on: ubuntu-latest
    needs: [setup-environment, check-new-submissions]
    if: needs.check-new-submissions.outputs.has_new_files == 'true' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install matplotlib seaborn pandas numpy
      
      - name: Prepare analysis environment
        run: |
          # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
          mkdir -p data/results/${{ needs.setup-environment.outputs.timestamp }}
          mkdir -p reports
          mkdir -p visualizations
          
          # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∏–ª–∏ –¥–µ–º–æ –¥–∞–Ω–Ω—ã–µ
          if [ "${{ needs.check-new-submissions.outputs.has_new_files }}" = "true" ]; then
            INPUT_DIR="uploads"
            echo "üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã"
          else
            INPUT_DIR="uploads_demo"
            echo "üé≠ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
          fi
          
          echo "input_dir=$INPUT_DIR" >> $GITHUB_ENV
      
      - name: Run plagiarism detection
        id: analysis
        env:
          THRESHOLD: ${{ github.event.inputs.threshold || '0.7' }}
        run: |
          echo "üß† –ó–∞–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ –ø–ª–∞–≥–∏–∞—Ç–∞..."
          
          # –°–æ–∑–¥–∞–µ–º Python —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
          cat > run_analysis.py << 'EOF'
import sys
sys.path.append('src')

from plagiarism_detector import PlagiarismDetector
import json
from datetime import datetime
import os

def main():
    print("üîç –ó–∞–ø—É—Å–∫–∞—é —Å–∏—Å—Ç–µ–º—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–ª–∞–≥–∏–∞—Ç–∞...")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    input_dir = os.getenv('INPUT_DIR', 'uploads_demo')
    threshold = float(os.getenv('THRESHOLD', '0.7'))
    timestamp = os.getenv('TIMESTAMP', datetime.now().strftime("%Y%m%d_%H%M%S"))
    
    print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {input_dir}")
    print(f"–ü–æ—Ä–æ–≥: {threshold}")
    print(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞: {timestamp}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
    detector = PlagiarismDetector()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        results = detector.analyze_directory(
            input_dir,
            threshold=threshold,
            algorithm='ensemble'
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results_dir = f"data/results/{timestamp}"
        os.makedirs(results_dir, exist_ok=True)
        
        results_file = f"{results_dir}/results.json"
        results.save_json(results_file)
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")
        
        # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
        summary = {
            "analysis_id": timestamp,
            "documents_analyzed": results.documents_analyzed,
            "suspicious_pairs": len(results.suspicious_pairs),
            "high_risk": results.high_risk_pairs,
            "medium_risk": results.medium_risk_pairs,
            "average_similarity": results.average_similarity,
            "threshold_used": threshold,
            "timestamp": datetime.now().isoformat()
        }
        
        summary_file = f"{results_dir}/summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"üìã –ö—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç: {summary_file}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
        print(f"::set-output name=results_dir::{results_dir}")
        print(f"::set-output name=results_file::{results_file}")
        print(f"::set-output name=summary_file::{summary_file}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
EOF
          
          # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
          python run_analysis.py
          
          # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
          RESULTS_DIR=$(python -c "
import json
import os
timestamp = '${{ needs.setup-environment.outputs.timestamp }}'
print(f'data/results/{timestamp}')
          ")
          
          echo "results_dir=$RESULTS_DIR" >> $GITHUB_OUTPUT
      
      - name: Generate visualizations
        run: |
          echo "üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏..."
          
          # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
          cat > create_viz.py << 'EOF'
import sys
sys.path.append('src')

from plagiarism_detector.visualizer import ResultVisualizer, visualize_from_json
import json
import os
from datetime import datetime

def main():
    timestamp = '${{ needs.setup-environment.outputs.timestamp }}'
    results_dir = f'data/results/{timestamp}'
    results_file = f'{results_dir}/results.json'
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑: {results_file}")
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results_data = json.load(f)
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        visualizer = ResultVisualizer()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
        heatmap_path = f'{results_dir}/heatmap.png'
        visualizer.create_heatmap(results_data, heatmap_path)
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é –¥–∏–∞–≥—Ä–∞–º–º—É
        summary_path = f'{results_dir}/summary_chart.png'
        visualizer.create_summary_chart(results_data, summary_path)
        
        print(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω—ã:")
        print(f"   üìà –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞: {heatmap_path}")
        print(f"   üìä –°–≤–æ–¥–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞: {summary_path}")
        
        # –°–æ–∑–¥–∞–µ–º HTML –æ—Ç—á–µ—Ç
        html_report = f'''<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>–û—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –ø–ª–∞–≥–∏–∞—Ç–∞ - {timestamp}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        .header {{ background: #4CAF50; color: white; padding: 20px; border-radius: 10px; }}
        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
        .stat-card {{ background: #f5f5f5; padding: 20px; border-radius: 10px; text-align: center; }}
        .stat-value {{ font-size: 2em; font-weight: bold; color: #4CAF50; }}
        .images {{ display: flex; flex-direction: column; gap: 20px; margin: 20px 0; }}
        .image-container {{ text-align: center; }}
        img {{ max-width: 100%; border: 1px solid #ddd; border-radius: 10px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
        th {{ background: #4CAF50; color: white; }}
        .high-risk {{ color: #e74c3c; font-weight: bold; }}
        .medium-risk {{ color: #f39c12; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üìä –û—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –ø–ª–∞–≥–∏–∞—Ç–∞</h1>
        <p>–í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞: {timestamp}</p>
        <p>–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏: {results_data.get("average_similarity", 0):.1%}</p>
    </div>
    
    <div class="stats">
        <div class="stat-card">
            <div class="stat-value">{results_data.get("documents_analyzed", 0)}</div>
            <div>–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ</div>
        </div>
        <div class="stat-card">
            <div class="stat-value">{results_data.get("suspicious_pairs", []) | length}</div>
            <div>–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä</div>
        </div>
        <div class="stat-card">
            <div class="stat-value">{results_data.get("high_risk_pairs", 0)}</div>
            <div>–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫</div>
        </div>
        <div class="stat-card">
            <div class="stat-value">{results_data.get("medium_risk_pairs", 0)}</div>
            <div>–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫</div>
        </div>
    </div>
    
    <div class="images">
        <div class="image-container">
            <h3>–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏</h3>
            <img src="heatmap.png" alt="–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞">
        </div>
        <div class="image-container">
            <h3>–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞</h3>
            <img src="summary_chart.png" alt="–°–≤–æ–¥–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞">
        </div>
    </div>
    
    <h3>–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤</h3>
    <table>
        <thead>
            <tr>
                <th>–î–æ–∫—É–º–µ–Ω—Ç A</th>
                <th>–î–æ–∫—É–º–µ–Ω—Ç B</th>
                <th>–°—Ö–æ–∂–µ—Å—Ç—å</th>
                <th>–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞</th>
            </tr>
        </thead>
        <tbody>
'''
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–∏
        suspicious_pairs = results_data.get("suspicious_pairs", [])
        for pair in suspicious_pairs[:10]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 –ø–∞—Ä–∞–º–∏
            similarity = pair.get("similarity", 0)
            if similarity > 0.8:
                risk_class = "high-risk"
                risk_text = "üî¥ –í—ã—Å–æ–∫–∏–π"
            elif similarity > 0.5:
                risk_class = "medium-risk"
                risk_text = "üü° –°—Ä–µ–¥–Ω–∏–π"
            else:
                risk_class = ""
                risk_text = "üü¢ –ù–∏–∑–∫–∏–π"
            
            html_report += f'''
            <tr>
                <td>{pair.get("document_a", "")}</td>
                <td>{pair.get("document_b", "")}</td>
                <td class="{risk_class}">{similarity:.1%}</td>
                <td>{risk_text}</td>
            </tr>
'''
        
        html_report += f'''
        </tbody>
    </table>
    
    <div style="margin-top: 40px; padding: 20px; background: #f5f5f5; border-radius: 10px;">
        <p><strong>–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:</strong> {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        <p><strong>Workflow ID:</strong> ${{{{ github.run_id }}}}</p>
    </div>
</body>
</html>'''
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –æ—Ç—á–µ—Ç
        html_path = f'{results_dir}/report.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        print(f"üìÑ HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {html_path}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π: {e}")

if __name__ == "__main__":
    main()
EOF
          
          # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
          python create_viz.py
      
      - name: Archive analyzed files
        run: |
          echo "üì¶ –ê—Ä—Ö–∏–≤–∏—Ä—É—é –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã..."
          
          ARCHIVE_DIR="data/archived/${{ needs.setup-environment.outputs.timestamp }}"
          mkdir -p "$ARCHIVE_DIR"
          
          # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤
          if [ -d "uploads" ] && [ "$(ls -A uploads 2>/dev/null)" ]; then
            mv uploads/* "$ARCHIVE_DIR/" 2>/dev/null || echo "–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏"
            echo "‚úÖ –§–∞–π–ª—ã –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω—ã –≤: $ARCHIVE_DIR"
          else
            echo "‚ÑπÔ∏è –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏"
          fi

  generate-reports:
    runs-on: ubuntu-latest
    needs: [setup-environment, run-plagiarism-analysis]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Generate PDF report
        if: ${{ github.event.inputs.generate_report != false }}
        run: |
          echo "üìÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é PDF –æ—Ç—á–µ—Ç..."
          
          # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º wkhtmltopdf –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PDF
          sudo apt-get update
          sudo apt-get install -y wkhtmltopdf
          
          RESULTS_DIR="${{ needs.run-plagiarism-analysis.outputs.results_dir || 'data/results/' }}${{ needs.setup-environment.outputs.timestamp }}"
          
          if [ -f "$RESULTS_DIR/report.html" ]; then
            wkhtmltopdf "$RESULTS_DIR/report.html" "$RESULTS_DIR/report.pdf"
            echo "‚úÖ PDF –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: $RESULTS_DIR/report.pdf"
          else
            echo "‚ÑπÔ∏è HTML –æ—Ç—á–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ PDF"
          fi
      
      - name: Create summary markdown
        run: |
          echo "üìã –°–æ–∑–¥–∞—é –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç –≤ Markdown..."
          
          TIMESTAMP="${{ needs.setup-environment.outputs.timestamp }}"
          SUMMARY_FILE="data/results/$TIMESTAMP/summary.json"
          
          if [ -f "$SUMMARY_FILE" ]; then
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ summary.json
            DOCS_COUNT=$(python -c "import json; data=json.load(open('$SUMMARY_FILE')); print(data.get('documents_analyzed', 0))")
            SUSPICIOUS=$(python -c "import json; data=json.load(open('$SUMMARY_FILE')); print(data.get('suspicious_pairs', 0))")
            HIGH_RISK=$(python -c "import json; data=json.load(open('$SUMMARY_FILE')); print(data.get('high_risk', 0))")
            AVG_SIM=$(python -c "import json; data=json.load(open('$SUMMARY_FILE')); print(data.get('average_similarity', 0))")
            
            # –°–æ–∑–¥–∞–µ–º Markdown –æ—Ç—á–µ—Ç
            cat > "data/results/$TIMESTAMP/README.md" << EOF
# üìä –û—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –ø–ª–∞–≥–∏–∞—Ç–∞

**–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞:** $TIMESTAMP  
**ID –∑–∞–ø—É—Å–∫–∞:** ${{ github.run_id }}

## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| üìÑ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ | $DOCS_COUNT |
| ‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä | $SUSPICIOUS |
| üî¥ –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ (>80%) | $HIGH_RISK |
| üìà –°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å | $(python -c "print('{:.1%}'.format($AVG_SIM))") |

## –§–∞–π–ª—ã –æ—Ç—á–µ—Ç–∞

- [results.json](results.json) - –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
- [summary.json](summary.json) - –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- [report.html](report.html) - HTML –æ—Ç—á–µ—Ç —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏
- [heatmap.png](heatmap.png) - –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
- [summary_chart.png](summary_chart.png) - –î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—Å–∫–æ–≤

## –°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è

1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º –ø–ª–∞–≥–∏–∞—Ç–∞
2. –£–≤–µ–¥–æ–º–∏—Ç—å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–µ–π –æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞—Ö
3. –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã

---
*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ GitHub Actions*
EOF
            
            echo "‚úÖ Markdown –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω"
          fi

  commit-and-deploy:
    runs-on: ubuntu-latest
    needs: [setup-environment, run-plagiarism-analysis, generate-reports]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Commit analysis results
        run: |
          echo "üíæ –ö–æ–º–º–∏—á—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞..."
          
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
          git add data/results/
          git add data/archived/
          
          # –ö–æ–º–º–∏—Ç–∏–º
          TIMESTAMP="${{ needs.setup-environment.outputs.timestamp }}"
          git commit -m "üìä Automated analysis results $TIMESTAMP

- –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: $(find data/results/$TIMESTAMP -name '*.json' -exec python -c \"import json,sys; d=json.load(open(sys.argv[1])); print(d.get('documents_analyzed', 0))\" {} \; 2>/dev/null | head -1)
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä: $(find data/results/$TIMESTAMP -name '*.json' -exec python -c \"import json,sys; d=json.load(open(sys.argv[1])); print(len(d.get('suspicious_pairs', [])))\" {} \; 2>/dev/null | head -1)
- Workflow ID: ${{ github.run_id }}" || echo "–ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∫–æ–º–º–∏—Ç–∞"
          
          # –ü—É—à–∏–º
          git push
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: data/results/${{ needs.setup-environment.outputs.timestamp }}
          destination_dir: reports/${{ needs.setup-environment.outputs.timestamp }}
          keep_files: false
      
      - name: Create Pull Request with findings
        if: ${{ needs.run-plagiarism-analysis.outputs.has_new_files == 'true' }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üîç –ü—Ä–æ–≤–µ—Ä—è—é –Ω–∞–ª–∏—á–∏–µ –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è –ø–ª–∞–≥–∏–∞—Ç–∞..."
          
          SUMMARY_FILE="data/results/${{ needs.setup-environment.outputs.timestamp }}/summary.json"
          
          if [ -f "$SUMMARY_FILE" ]; then
            HIGH_RISK=$(python -c "
import json
with open('$SUMMARY_FILE') as f:
    data = json.load(f)
    high_risk = data.get('high_risk', 0)
    if high_risk > 0:
        print('true')
    else:
        print('false')
            ")
            
            if [ "$HIGH_RISK" = "true" ]; then
              echo "‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ø–ª–∞–≥–∏–∞—Ç–∞, —Å–æ–∑–¥–∞—é Pull Request –¥–ª—è —Ä–µ–≤—å—é..."
              
              # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ç–∫—É
              BRANCH_NAME="plagiarism-review-${{ needs.setup-environment.outputs.timestamp }}"
              git checkout -b "$BRANCH_NAME"
              
              # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –¥–ª—è —Ä–µ–≤—å—é
              cat > "REVIEW_NEEDED.md" << EOF
# üìã –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–≤—å—é: –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–ª–∞–≥–∏–∞—Ç

## –î–µ—Ç–∞–ª–∏ –∞–Ω–∞–ª–∏–∑–∞
- **–í—Ä–µ–º—è:** ${{ needs.setup-environment.outputs.timestamp }}
- **–î–æ–∫—É–º–µ–Ω—Ç–æ–≤:** $(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('documents_analyzed', 0))")
- **–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫:** $(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('high_risk', 0))")
- **–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫:** $(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('medium_risk', 0))")

## –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã
$(python -c "
import json
with open('data/results/${{ needs.setup-environment.outputs.timestamp }}/results.json') as f:
    data = json.load(f)
    for pair in data.get('suspicious_pairs', [])[:5]:
        if pair.get('similarity', 0) > 0.7:
            print(f'- **{pair.get(\"document_a\")}** ‚Üî **{pair.get(\"document_b\")}**: {pair.get(\"similarity\", 0):.1%}")
")

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é
2. –°–≤—è–∑–∞—Ç—å—Å—è —Å –∞–≤—Ç–æ—Ä–∞–º–∏ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
3. –ü—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ —Å–∞–Ω–∫—Ü–∏—è—Ö
4. –û–±–Ω–æ–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Å–∏—Å—Ç–µ–º–µ

## –°—Å—ã–ª–∫–∏
- [–ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
- [GitHub Pages](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/reports/${{ needs.setup-environment.outputs.timestamp }}/)

---
*–°–æ–∑–¥–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏—Å—Ç–µ–º–æ–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–ª–∞–≥–∏–∞—Ç–∞*
EOF
              
              git add REVIEW_NEEDED.md
              git commit -m "üìã –î–æ–±–∞–≤–ª–µ–Ω —Ñ–∞–π–ª –¥–ª—è —Ä–µ–≤—å—é –ø–ª–∞–≥–∏–∞—Ç–∞"
              git push origin "$BRANCH_NAME"
              
              # –°–æ–∑–¥–∞–µ–º Pull Request
              gh pr create \
                --title "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–≤—å—é: –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–ª–∞–≥–∏–∞—Ç (${{ needs.setup-environment.outputs.timestamp }})" \
                --body-file REVIEW_NEEDED.md \
                --base main \
                --head "$BRANCH_NAME" \
                --label "plagiarism-review" \
                --label "automated"
            fi
          fi
      
      - name: Create GitHub Issue for manual review
        if: ${{ needs.run-plagiarism-analysis.outputs.has_new_files == 'true' }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üìù –°–æ–∑–¥–∞—é Issue –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏..."
          
          SUMMARY_FILE="data/results/${{ needs.setup-environment.outputs.timestamp }}/summary.json"
          
          if [ -f "$SUMMARY_FILE" ]; then
            SUSPICIOUS_COUNT=$(python -c "
import json
with open('$SUMMARY_FILE') as f:
    data = json.load(f)
    print(data.get('suspicious_pairs', 0))
            ")
            
            if [ "$SUSPICIOUS_COUNT" -gt 0 ]; then
              gh issue create \
                --title "üìã –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: $SUSPICIOUS_COUNT –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä (${{ needs.setup-environment.outputs.timestamp }})" \
                --body "## üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

**–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞:** ${{ needs.setup-environment.outputs.timestamp }}
**–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä:** $SUSPICIOUS_COUNT
**–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** $(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('documents_analyzed', 0))")

### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
- [–ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
- [–û—Ç–∫—Ä—ã—Ç—å –Ω–∞ GitHub Pages](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/reports/${{ needs.setup-environment.outputs.timestamp }}/)

### üéØ –î–µ–π—Å—Ç–≤–∏—è
1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã –≤—Ä—É—á–Ω—É—é
2. –ü—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏—è—Ö
3. –ó–∞–∫—Ä—ã—Ç—å issue –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏

---
*–°–æ–∑–¥–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏—Å—Ç–µ–º–æ–π –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–ª–∞–≥–∏–∞—Ç–∞*" \
                --label "manual-review" \
                --label "plagiarism" \
                --assignee "${{ github.actor }}"
            fi
          fi

  send-notifications:
    runs-on: ubuntu-latest
    needs: [setup-environment, run-plagiarism-analysis]
    if: always()
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Send summary to workflow
        run: |
          echo "üì¢ –û—Ç–ø—Ä–∞–≤–ª—è—é —Å–≤–æ–¥–∫—É –ø–æ –∞–Ω–∞–ª–∏–∑—É..."
          
          TIMESTAMP="${{ needs.setup-environment.outputs.timestamp }}"
          SUMMARY_FILE="data/results/$TIMESTAMP/summary.json"
          
          if [ -f "$SUMMARY_FILE" ]; then
            DOCS=$(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('documents_analyzed', 0))")
            SUSPICIOUS=$(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('suspicious_pairs', 0))")
            HIGH_RISK=$(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print(d.get('high_risk', 0))")
            AVG_SIM=$(python -c "import json; d=json.load(open('$SUMMARY_FILE')); print('{:.1%}'.format(d.get('average_similarity', 0)))")
            
            echo "## üìä –°–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–∞–≥–∏–∞—Ç–∞" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**–í—Ä–µ–º—è:** $TIMESTAMP" >> $GITHUB_STEP_SUMMARY
            echo "**Workflow:** [${{ github.workflow }} #${{ github.run_number }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |" >> $GITHUB_STEP_SUMMARY
            echo "|---------|----------|" >> $GITHUB_STEP_SUMMARY
            echo "| üìÑ –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ | $DOCS |" >> $GITHUB_STEP_SUMMARY
            echo "| ‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä | $SUSPICIOUS |" >> $GITHUB_STEP_SUMMARY
            echo "| üî¥ –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ | $HIGH_RISK |" >> $GITHUB_STEP_SUMMARY
            echo "| üìà –°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å | $AVG_SIM |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üîó –°—Å—ã–ª–∫–∏" >> $GITHUB_STEP_SUMMARY
            echo "- [üìä –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç](https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/reports/$TIMESTAMP/)" >> $GITHUB_STEP_SUMMARY
            echo "- [‚öôÔ∏è Workflow –¥–µ—Ç–∞–ª–∏](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏*" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Send Slack notification
        if: ${{ github.event.inputs.notify_slack == true && secrets.SLACK_WEBHOOK_URL }}
        uses: slackapi/slack-github-action@v1.24.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "üìä –ê–Ω–∞–ª–∏–∑ –ø–ª–∞–≥–∏–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*–í—Ä–µ–º—è:*\n${{ needs.setup-environment.outputs.timestamp }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*–î–æ–∫—É–º–µ–Ω—Ç–æ–≤:*\n$(python -c \"import json,os; f=os.path.join('data/results', '${{ needs.setup-environment.outputs.timestamp }}', 'summary.json'); d=json.load(open(f)); print(d.get('documents_analyzed', 0))\")"
                    }
                  ]
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ä:*\n$(python -c \"import json,os; f=os.path.join('data/results', '${{ needs.setup-environment.outputs.timestamp }}', 'summary.json'); d=json.load(open(f)); print(d.get('suspicious_pairs', 0))\")"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫:*\n$(python -c \"import json,os; f=os.path.join('data/results', '${{ needs.setup-environment.outputs.timestamp }}', 'summary.json'); d=json.load(open(f)); print(d.get('high_risk', 0))\")"
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "üìä –û—Ç–∫—Ä—ã—Ç—å –æ—Ç—á–µ—Ç",
                        "emoji": true
                      },
                      "url": "https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/reports/${{ needs.setup-environment.outputs.timestamp }}/"
                    },
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "‚öôÔ∏è Workflow",
                        "emoji": true
                      },
                      "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

  cleanup:
    runs-on: ubuntu-latest
    if: always()
    needs: [commit-and-deploy, send-notifications]
    
    steps:
      - name: Clean up temporary files
        run: |
          echo "üßπ –û—á–∏—â–∞—é –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã..."
          
          # –£–¥–∞–ª—è–µ–º –¥–µ–º–æ —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã
          rm -rf uploads_demo 2>/dev/null || true
          
          echo "‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞"
      
      - name: Update workflow status
        run: |
          echo "üèÅ Workflow –∑–∞–≤–µ—Ä—à–µ–Ω!"
          echo "–°—Ç–∞—Ç—É—Å: ${{ job.status }}"
          
          if [ "${{ job.status }}" = "success" ]; then
            echo "‚úÖ –í—Å–µ
